{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este projeto é uma análise exploratória do dataset Intel Image Classification, disponível no Kaggle. O dataset contém 25 mil imagens de 6 classes diferentes, sendo elas: buildings, forest, glacier, mountain, sea e street. O objetivo é classificar as imagens de acordo com a classe a qual pertencem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-05 15:05:43.928135: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-05 15:05:44.028338: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-05 15:05:44.028413: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-05 15:05:44.032897: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-05 15:05:44.048197: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-05 15:05:44.050739: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-05 15:05:45.726546: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Flatten, Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14034 files belonging to 6 classes.\n",
      "Found 3000 files belonging to 6 classes.\n",
      "Found 7301 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = keras.utils.image_dataset_from_directory('./seg_train', batch_size=64, image_size=(150, 150),  label_mode='categorical')\n",
    "validation_dataset = keras.utils.image_dataset_from_directory('./seg_test', batch_size=64, image_size=(150, 150),  label_mode='categorical')\n",
    "prediction_dataset = keras.utils.image_dataset_from_directory('./seg_pred', batch_size=64,  shuffle=True, image_size=(150, 150))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratore Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como veremos abaixo, o dataset é composto por imagens de 150x150 pixels, coloridas e com 3 canais (RGB). Além disso, o dataset é balanceado, ou seja, possui a mesma quantidade de imagens para cada classe.\n",
    "Exibiremos algumas imagens do dataset para melhor entendimento.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Describe some characteristics of the dataset.\n",
    "# print(train_dataset.class_names)\n",
    "# print(validation_dataset.class_names)\n",
    "# print(train_dataset)\n",
    "# print(validation_dataset)\n",
    "\n",
    "# # Visualize one of the images in the dataset.\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for images, labels in train_dataset.take(1):\n",
    "#     for i in range(9):\n",
    "#         ax = plt.subplot(3, 3, i + 1)\n",
    "#         plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "#         plt.title(train_dataset.class_names[labels[i]])\n",
    "#         plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_networks = [\n",
    "    {\n",
    "        'description': 'Conv2D_MaxPooling_Conv2D',\n",
    "        'model': Sequential([\n",
    "                    Convolution2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "                    MaxPooling2D(pool_size=(2, 2)),\n",
    "                    Convolution2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
    "                    Flatten(input_shape=(150, 150, 3)),\n",
    "                    Dense(units=6, activation='softmax')\n",
    "                    ]\n",
    "                ),\n",
    "        'epochs': 2,\n",
    "        # 'steps_per_epoch': 100,\n",
    "        # 'validation_steps': 10,\n",
    "        'optimizer': Adam(learning_rate=0.0001),\n",
    "        'loss_function': 'categorical_crossentropy',\n",
    "        'accuracy': None,\n",
    "        'loss': None,\n",
    "        'training_time': None,\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': 'Conv2D_MaxPooling_Conv2D', 'model': <keras.src.engine.sequential.Sequential object at 0x7f10a29b81c0>, 'epochs': 2, 'optimizer': <keras.src.optimizers.adam.Adam object at 0x7f10a29b8130>, 'loss_function': 'categorical_crossentropy', 'accuracy': None, 'loss': None, 'training_time': None}\n"
     ]
    }
   ],
   "source": [
    "for nn in neural_networks:\n",
    "    model = nn['model']\n",
    "    print(nn)\n",
    "    model.compile(optimizer=nn['optimizer'], loss=nn['loss_function'], metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 - 268s - loss: 22.3919 - accuracy: 0.4963 - val_loss: 5.2914 - val_accuracy: 0.5647 - 268s/epoch - 1s/step\n",
      "Epoch 2/2\n",
      "220/220 - 214s - loss: 2.0736 - accuracy: 0.6994 - val_loss: 2.6276 - val_accuracy: 0.6440 - 214s/epoch - 971ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gxara/.pyenv/versions/3.9.0/envs/ml/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/gxara/.pyenv/versions/3.9.0/envs/ml/lib/python3.9/site-packages/keras/src/engine/training.py\", line 2066, in test_function  *\n        return step_function(self, iterator)\n    File \"/home/gxara/.pyenv/versions/3.9.0/envs/ml/lib/python3.9/site-packages/keras/src/engine/training.py\", line 2049, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/gxara/.pyenv/versions/3.9.0/envs/ml/lib/python3.9/site-packages/keras/src/engine/training.py\", line 2037, in run_step  **\n        outputs = model.test_step(data)\n    File \"/home/gxara/.pyenv/versions/3.9.0/envs/ml/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1919, in test_step\n        self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/gxara/.pyenv/versions/3.9.0/envs/ml/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/home/gxara/.pyenv/versions/3.9.0/envs/ml/lib/python3.9/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/gxara/.pyenv/versions/3.9.0/envs/ml/lib/python3.9/site-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/gxara/.pyenv/versions/3.9.0/envs/ml/lib/python3.9/site-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/gxara/.pyenv/versions/3.9.0/envs/ml/lib/python3.9/site-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/home/gxara/.pyenv/versions/3.9.0/envs/ml/lib/python3.9/site-packages/keras/src/backend.py\", line 5573, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 6) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/gxara/deep_learning/project.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gxara/deep_learning/project.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39mfit(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gxara/deep_learning/project.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     train_dataset,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gxara/deep_learning/project.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     validation_data\u001b[39m=\u001b[39mvalidation_dataset,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gxara/deep_learning/project.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     epochs\u001b[39m=\u001b[39mnn[\u001b[39m'\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gxara/deep_learning/project.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gxara/deep_learning/project.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gxara/deep_learning/project.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39mmodels/\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m nn[\u001b[39m'\u001b[39m\u001b[39mdescription\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.h5\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/gxara/deep_learning/project.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m model\u001b[39m.\u001b[39;49mevaluate(prediction_dataset, verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.0/envs/ml/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file0edf4362.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__test_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/gxara/.pyenv/versions/3.9.0/envs/ml/lib/python3.9/site-packages/keras/src/engine/training.py\", line 2066, in test_function  *\n        return step_function(self, iterator)\n    File \"/home/gxara/.pyenv/versions/3.9.0/envs/ml/lib/python3.9/site-packages/keras/src/engine/training.py\", line 2049, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/gxara/.pyenv/versions/3.9.0/envs/ml/lib/python3.9/site-packages/keras/src/engine/training.py\", line 2037, in run_step  **\n        outputs = model.test_step(data)\n    File \"/home/gxara/.pyenv/versions/3.9.0/envs/ml/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1919, in test_step\n        self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/gxara/.pyenv/versions/3.9.0/envs/ml/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/home/gxara/.pyenv/versions/3.9.0/envs/ml/lib/python3.9/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/gxara/.pyenv/versions/3.9.0/envs/ml/lib/python3.9/site-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/gxara/.pyenv/versions/3.9.0/envs/ml/lib/python3.9/site-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/gxara/.pyenv/versions/3.9.0/envs/ml/lib/python3.9/site-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/home/gxara/.pyenv/versions/3.9.0/envs/ml/lib/python3.9/site-packages/keras/src/backend.py\", line 5573, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 6) are incompatible\n"
     ]
    }
   ],
   "source": [
    "for nn in neural_networks:\n",
    "    model = nn['model']\n",
    "    model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=validation_dataset,\n",
    "        epochs=nn['epochs'],\n",
    "        verbose=2\n",
    "    )\n",
    "    model.save('models/' + nn['description'] + '.h5')\n",
    "    model.evaluate(prediction_dataset, verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = model.predict(prediction_dataset, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# y_pred = np.argmax(predictions, axis=1)\n",
    "# y_true = np.concatenate([y for x, y in prediction_dataset], axis=0)\n",
    "# cm = confusion_matrix(y_true, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
